{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.697442411Z",
     "start_time": "2025-12-20T04:01:39.693760399Z"
    }
   },
   "source": [
    "from typing import Sequence\n",
    "import k2\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Decoding multiple test phrases for a single keyword",
   "id": "fd83a285c6c487a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.739926191Z",
     "start_time": "2025-12-20T04:01:39.697689870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 6\n",
    "padded_seq_len = 20\n",
    "actual_seq_lens = [20, 15, 15, 20, 10, 13]\n",
    "keyword_len = 5\n",
    "\n",
    "# probs = torch.randint(1, 20, (batch_size, padded_seq_len, keyword_len))\n",
    "probs = torch.randn((batch_size, padded_seq_len, keyword_len))\n",
    "for i, actual_seq_len in enumerate(actual_seq_lens):\n",
    "    probs[i, actual_seq_len:] = 0\n",
    "# probs = probs.log()\n",
    "probs=probs.to(0)\n",
    "print(probs.shape, probs.device)"
   ],
   "id": "be2ab9503dffe262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3]) cuda:0\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.782795552Z",
     "start_time": "2025-12-20T04:01:39.740144655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_dense_fsa(log_scores, seq_lens):\n",
    "    N = log_scores.shape[0]\n",
    "\n",
    "    seq_idcs = torch.arange(N, dtype=torch.int32)\n",
    "    start_frames = torch.zeros(N, dtype=torch.int32)\n",
    "    durations = torch.tensor(seq_lens, dtype=torch.int32)\n",
    "\n",
    "    durations_sorted, indices_sorted = torch.sort(durations, descending=True)\n",
    "    seq_idcs_sorted = seq_idcs[indices_sorted]\n",
    "    start_frames_sorted = start_frames[indices_sorted]\n",
    "    log_scores_sorted = log_scores[indices_sorted]\n",
    "\n",
    "    mean_log_score = log_scores_sorted.mean(dim=-1, keepdim=True)\n",
    "    log_scores_w_mean = torch.cat([log_scores_sorted, mean_log_score], dim=-1)\n",
    "\n",
    "    supervision_segments = torch.stack(\n",
    "        [seq_idcs_sorted, start_frames_sorted, durations_sorted],\n",
    "        dim=1\n",
    "    )\n",
    "\n",
    "    fsa = k2.DenseFsaVec(log_scores_w_mean, supervision_segments)\n",
    "    return fsa"
   ],
   "id": "b2ab8011f8938f20",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.826230143Z",
     "start_time": "2025-12-20T04:01:39.783101561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dense_fsa = make_dense_fsa(probs, actual_seq_lens)\n",
    "dense_fsa.dim0()"
   ],
   "id": "ed4d4524a5fbfd92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.870211459Z",
     "start_time": "2025-12-20T04:01:39.826504282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_query_fsa_str(keyword_len: int) -> str:\n",
    "    \"\"\"\n",
    "    Helper function for `make_query_fsa` that generates a string\n",
    "    interpretable by `k2` as an FSA.\n",
    "    Args:\n",
    "        keyword_len: int indicating number of states in keyword query\n",
    "    Returns:\n",
    "        query_fsa_str: string representation of FSA accepting keyword labels\n",
    "\n",
    "    \"\"\"\n",
    "    if type(keyword_len) is torch.Tensor:\n",
    "        keyword_len = keyword_len.item()\n",
    "\n",
    "    arc_template = \"{curr_state} {next_state} {label} {score}\"\n",
    "    initial_self_arc = arc_template.format(\n",
    "        curr_state=0,\n",
    "        next_state=0,\n",
    "        label=keyword_len,\n",
    "        score=0.0,\n",
    "    )\n",
    "    arc_list = [initial_self_arc]\n",
    "\n",
    "    for i in range(keyword_len-1):\n",
    "        curr = str(i)+\" \"\n",
    "        nxt = str(i+1)+\" \"\n",
    "        # TODO: implement insertion and deletion arcs Ã -la Noise-Robust CTC (Xi et al 2025)\n",
    "        arc = arc_template.format(\n",
    "            curr_state=curr,\n",
    "            next_state=nxt,\n",
    "            label=curr,\n",
    "            score=0.0,\n",
    "        )\n",
    "        arc_list.append(arc)\n",
    "\n",
    "    final_self_arc = arc_template.format(\n",
    "        curr_state=keyword_len-1,\n",
    "        next_state=keyword_len-1,\n",
    "        label=keyword_len,\n",
    "        score=0.0,\n",
    "    )\n",
    "    final_arc = arc_template.format(\n",
    "        curr_state=keyword_len-1,\n",
    "        next_state=keyword_len,\n",
    "        label=-1,\n",
    "        score=0.0,\n",
    "    )\n",
    "    final_state = f\"{keyword_len}\"\n",
    "\n",
    "    arc_list.append(final_self_arc)\n",
    "    arc_list.append(final_arc)\n",
    "    arc_list.append(final_state)\n",
    "\n",
    "    query_fsa_str = \"\\n\".join(arc_list)\n",
    "    return query_fsa_str\n",
    "query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "print(query_fsa_str)"
   ],
   "id": "3622cb4657d5c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 3 0.0\n",
      "0  1  0  0.0\n",
      "1  2  1  0.0\n",
      "2 2 3 0.0\n",
      "2 3 -1 0.0\n",
      "3\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.913129351Z",
     "start_time": "2025-12-20T04:01:39.870494665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_query_fsa(keyword_len, batch_size=None):\n",
    "    query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "    fsa = k2.Fsa.from_str(query_fsa_str).to(device)\n",
    "\n",
    "    if batch_size is not None:\n",
    "        fsa = k2.create_fsa_vec([fsa]*batch_size)\n",
    "    return fsa\n",
    "\n",
    "query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "query_fsa.shape"
   ],
   "id": "d8fc1b39b1076164",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:39.956794058Z",
     "start_time": "2025-12-20T04:01:39.913373834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_single_keyword(probs, seq_lens):\n",
    "    dense_fsa = make_dense_fsa(probs, seq_lens)\n",
    "    keyword_len = probs.shape[-1]\n",
    "    query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    labels = best_path.labels\n",
    "    return score, labels\n",
    "\n",
    "decode_single_keyword(probs, actual_seq_lens)"
   ],
   "id": "51952e7c934c1652",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.4606,  0.7751, -0.2038], device='cuda:0', dtype=torch.float64),\n",
       " tensor([ 3,  0,  1, -1,  3,  0,  1, -1,  3,  0,  1, -1], device='cuda:0',\n",
       "        dtype=torch.int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(tensor([ 7.8563, 20.5448,  4.5942,  9.5775,  3.4156,  1.4157], device='cuda:0',\n",
    "        dtype=torch.float64),\n",
    " tensor([ 0,  0,  0,  0,  0,  1,  2,  3,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0, -1,  0,  0,  1,  0,  0,  0,  0,  0,  2,  3,  4,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0, -1,  0,  1,  2,  3,  4,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  2,  0,  3,  0,  4,\n",
    "          0, -1,  0,  1,  0,  0,  2,  0,  3,  0,  0,  4,  0,  0,  0, -1,  0,  0,\n",
    "          1,  0,  2,  3,  0,  4,  0,  0, -1], device='cuda:0',\n",
    "        dtype=torch.int32))"
   ],
   "id": "ddd1f51163eff2b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batched keyword decoding",
   "id": "2bb8322ead485e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.000084656Z",
     "start_time": "2025-12-20T04:01:39.957071683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_query_graph(keyword_lens, batch_size):\n",
    "    \"\"\"\n",
    "    Creates an FSA Vector with `batch_size` repetitions\n",
    "    of each query graph.\n",
    "\n",
    "    Arguments:\n",
    "        keyword_lens: list of lengths of each query graph\n",
    "        batch_size: number of test phrases in batch\n",
    "    Returns:\n",
    "        FSA vector of queries\n",
    "    \"\"\"\n",
    "    expanded_lens = torch.tensor(keyword_lens)\\\n",
    "        .unsqueeze(1)\\\n",
    "        .repeat(1, batch_size)\\\n",
    "        .view(-1)\\\n",
    "        .to(torch.int32)\n",
    "    fsa_list = []\n",
    "    for keyword_len in expanded_lens:\n",
    "        fsa_list.append(make_query_fsa(keyword_len))\n",
    "    query_graph = k2.create_fsa_vec(fsa_list)\n",
    "    return query_graph\n",
    "\n",
    "keyword_lens = [10, 5, 9]\n",
    "padded_keyword_len = max(keyword_lens)\n",
    "num_keywords = len(keyword_lens)\n",
    "\n",
    "query_graph = prepare_query_graph(keyword_lens, batch_size)\n",
    "query_graph.shape"
   ],
   "id": "fcfeaad645ea6b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, None, None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.044134642Z",
     "start_time": "2025-12-20T04:01:40.000299192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_dense_fsa_batch(prob_matrices: torch.Tensor, seq_lens: Sequence[int]):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        prob_matrices: tensor of shape K*T*W_k*W_t, where K is the number of queries,\n",
    "            T the number of test phrases, W_k the number of padded windows in each\n",
    "            query and W_t the number of padded windows in each test phrase\n",
    "    Returns:\n",
    "        Dense FSA of query probabilities\n",
    "    \"\"\"\n",
    "    # prob_matrices needs to be reshaped from K*T*W_k*W_t\n",
    "    # to (K*T)*W_t*W_k\n",
    "    probs_flattened = prob_matrices.flatten(0,1)\n",
    "    probs_transposed = probs_flattened.transpose(1,2)\n",
    "    probs_transposed = probs_transposed.to(device)\n",
    "    if type(seq_lens) is torch.Tensor:\n",
    "        seq_lens = seq_lens.tolist()\n",
    "    new_seq_lens=seq_lens*num_keywords\n",
    "    return make_dense_fsa(probs_transposed, new_seq_lens)\n",
    "\n",
    "\n",
    "prob_matrices = torch.randn((num_keywords, batch_size, padded_keyword_len, padded_seq_len))\n",
    "dense_fsa = prepare_dense_fsa_batch(prob_matrices, actual_seq_lens)\n",
    "dense_fsa.dim0(), dense_fsa.device"
   ],
   "id": "8be31be3fdd3ceac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.087799709Z",
     "start_time": "2025-12-20T04:01:40.044456241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_keyword_batch(prob_matrices, keyword_lens, seq_lens):\n",
    "    num_keywords = prob_matrices.shape[0]\n",
    "    batch_size = prob_matrices.shape[1]\n",
    "    query_fsa = prepare_query_graph(keyword_lens, batch_size)\n",
    "    dense_fsa = prepare_dense_fsa_batch(prob_matrices, seq_lens)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    score = score.reshape(num_keywords, batch_size)\n",
    "    labels = best_path.labels\n",
    "    return score, labels"
   ],
   "id": "27e89503cc8c0118",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.131189856Z",
     "start_time": "2025-12-20T04:01:40.088056385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores, labels = decode_keyword_batch(prob_matrices, keyword_lens, actual_seq_lens)\n",
    "scores.shape, labels.shape"
   ],
   "id": "32fb1017fde51c80",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([0]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.174107137Z",
     "start_time": "2025-12-20T04:01:40.131430492Z"
    }
   },
   "cell_type": "code",
   "source": "scores",
   "id": "656626dcfd250567",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.216935260Z",
     "start_time": "2025-12-20T04:01:40.174287930Z"
    }
   },
   "cell_type": "code",
   "source": "prob_matrices.max()",
   "id": "26ff567c85b0de78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7650)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T04:01:40.260043453Z",
     "start_time": "2025-12-20T04:01:40.217204800Z"
    }
   },
   "cell_type": "code",
   "source": "actual_seq_lens",
   "id": "bc3722ed32254904",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
