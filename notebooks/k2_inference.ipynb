{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.629508047Z",
     "start_time": "2025-12-17T02:11:08.880782089Z"
    }
   },
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import k2\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Decoding multiple test phrases for a single keyword",
   "id": "fd83a285c6c487a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.738644796Z",
     "start_time": "2025-12-17T02:11:09.631291626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 6\n",
    "padded_seq_len = 20\n",
    "actual_seq_lens = [20, 15, 15, 20, 10, 13]\n",
    "keyword_len = 5\n",
    "\n",
    "# probs = torch.randint(1, 20, (batch_size, padded_seq_len, keyword_len))\n",
    "probs = torch.randn((batch_size, padded_seq_len, keyword_len))\n",
    "for i, actual_seq_len in enumerate(actual_seq_lens):\n",
    "    probs[i, actual_seq_len:] = 0\n",
    "# probs = probs.log()\n",
    "probs=probs.to(0)\n",
    "print(probs.shape, probs.device)"
   ],
   "id": "be2ab9503dffe262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 5]) cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.784367509Z",
     "start_time": "2025-12-17T02:11:09.739741494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_dense_fsa(log_scores, seq_lens):\n",
    "    N = log_scores.shape[0]\n",
    "\n",
    "    seq_idcs = torch.arange(N, dtype=torch.int32)\n",
    "    start_frames = torch.zeros(N, dtype=torch.int32)\n",
    "    durations = torch.tensor(seq_lens, dtype=torch.int32)\n",
    "\n",
    "    durations_sorted, indices_sorted = torch.sort(durations, descending=True)\n",
    "    seq_idcs_sorted = seq_idcs[indices_sorted]\n",
    "    start_frames_sorted = start_frames[indices_sorted]\n",
    "    log_scores_sorted = log_scores[indices_sorted]\n",
    "\n",
    "    supervision_segments = torch.stack([seq_idcs_sorted, start_frames_sorted, durations_sorted], dim=1)\n",
    "\n",
    "    fsa = k2.DenseFsaVec(log_scores_sorted, supervision_segments)\n",
    "    return fsa"
   ],
   "id": "b2ab8011f8938f20",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.831526252Z",
     "start_time": "2025-12-17T02:11:09.784939723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dense_fsa = make_dense_fsa(probs, actual_seq_lens)\n",
    "dense_fsa.dim0()"
   ],
   "id": "ed4d4524a5fbfd92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.877598267Z",
     "start_time": "2025-12-17T02:11:09.832562135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_query_fsa_str(keyword_len):\n",
    "    if type(keyword_len) is torch.Tensor:\n",
    "        keyword_len = keyword_len.item()\n",
    "    query_fsa_str = \"\"\n",
    "    for i in range(keyword_len-1):\n",
    "        curr = str(i)+\" \"\n",
    "        nxt = str(i+1)+\" \"\n",
    "        #           src_state   dest_state  label   score\n",
    "        self_arc=   curr +      curr +      curr +  \"0.0\\n\"\n",
    "        arc=        curr +      nxt +       curr +  \"0.0\\n\"\n",
    "        query_fsa_str+=self_arc\n",
    "        query_fsa_str+=arc\n",
    "\n",
    "    penult = str(keyword_len-1)+\" \"\n",
    "    final = str(keyword_len)+\" \"\n",
    "    #                   src_state   dest_state  label   score\n",
    "    final_arc=          penult +    final +     \"-1 \" + \"0.0\\n\"\n",
    "    query_fsa_str +=  final_arc\n",
    "    query_fsa_str += final\n",
    "    return query_fsa_str\n",
    "query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "print(query_fsa_str)"
   ],
   "id": "3622cb4657d5c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0.0\n",
      "0 1 0 0.0\n",
      "1 1 1 0.0\n",
      "1 2 1 0.0\n",
      "2 2 2 0.0\n",
      "2 3 2 0.0\n",
      "3 3 3 0.0\n",
      "3 4 3 0.0\n",
      "4 5 -1 0.0\n",
      "5 \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.926138888Z",
     "start_time": "2025-12-17T02:11:09.878149792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_query_fsa(keyword_len, batch_size=None):\n",
    "    query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "    fsa = k2.Fsa.from_str(query_fsa_str).to(device)\n",
    "\n",
    "    if batch_size is not None:\n",
    "        fsa = k2.create_fsa_vec([fsa]*batch_size)\n",
    "    return fsa\n",
    "\n",
    "query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "query_fsa.shape"
   ],
   "id": "d8fc1b39b1076164",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:09.993613616Z",
     "start_time": "2025-12-17T02:11:09.926705421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_single_keyword(probs, seq_lens):\n",
    "    dense_fsa = make_dense_fsa(probs, seq_lens)\n",
    "    keyword_len = probs.shape[-1]\n",
    "    query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    labels = best_path.labels\n",
    "    return score, labels\n",
    "\n",
    "decode_single_keyword(probs, actual_seq_lens)"
   ],
   "id": "51952e7c934c1652",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12.8426,  1.6298,  6.9752,  9.7784,  4.9014,  4.8300], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([ 0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,\n",
       "          3,  3, -1,  0,  1,  1,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3, -1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          2,  3,  3, -1,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  2,  2,  2,  2,\n",
       "          3, -1,  0,  0,  1,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3, -1,  0,  0,\n",
       "          0,  0,  0,  1,  1,  2,  2,  3, -1], device='cuda:0',\n",
       "        dtype=torch.int32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(tensor([ 7.8563, 20.5448,  4.5942,  9.5775,  3.4156,  1.4157], device='cuda:0',\n",
    "        dtype=torch.float64),\n",
    " tensor([ 0,  0,  0,  0,  0,  1,  2,  3,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0, -1,  0,  0,  1,  0,  0,  0,  0,  0,  2,  3,  4,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0, -1,  0,  1,  2,  3,  4,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  2,  0,  3,  0,  4,\n",
    "          0, -1,  0,  1,  0,  0,  2,  0,  3,  0,  0,  4,  0,  0,  0, -1,  0,  0,\n",
    "          1,  0,  2,  3,  0,  4,  0,  0, -1], device='cuda:0',\n",
    "        dtype=torch.int32))"
   ],
   "id": "ddd1f51163eff2b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batched keyword decoding",
   "id": "2bb8322ead485e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:10.038959174Z",
     "start_time": "2025-12-17T02:11:09.994234622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_query_graph(keyword_lens, batch_size):\n",
    "    \"\"\"\n",
    "    Creates an FSA Vector with `batch_size` repetitions\n",
    "    of each query graph.\n",
    "\n",
    "    Arguments:\n",
    "        keyword_lens: list of lengths of each query graph\n",
    "        batch_size: number of test phrases in batch\n",
    "    Returns:\n",
    "        FSA vector of queries\n",
    "    \"\"\"\n",
    "    expanded_lens = torch.tensor(keyword_lens)\\\n",
    "        .unsqueeze(1)\\\n",
    "        .repeat(1, batch_size)\\\n",
    "        .view(-1)\\\n",
    "        .to(torch.int32)\n",
    "    fsa_list = []\n",
    "    for keyword_len in expanded_lens:\n",
    "        fsa_list.append(make_query_fsa(keyword_len))\n",
    "    query_graph = k2.create_fsa_vec(fsa_list)\n",
    "    return query_graph\n",
    "\n",
    "keyword_lens = [10, 5, 9]\n",
    "padded_keyword_len = max(keyword_lens)\n",
    "num_keywords = len(keyword_lens)\n",
    "\n",
    "query_graph = prepare_query_graph(keyword_lens, batch_size)\n",
    "query_graph.shape"
   ],
   "id": "fcfeaad645ea6b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:11:10.085051107Z",
     "start_time": "2025-12-17T02:11:10.039820396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_dense_fsa_batch(prob_matrices: torch.Tensor, seq_lens: Sequence[int]):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        prob_matrices: tensor of shape K*T*W_k*W_t, where K is the number of queries,\n",
    "            T the number of test phrases, W_k the number of padded windows in each\n",
    "            query and W_t the number of padded windows in each test phrase\n",
    "    Returns:\n",
    "        Dense FSA of query probabilities\n",
    "    \"\"\"\n",
    "    # prob_matrices needs to be reshaped from K*T*W_k*W_t\n",
    "    # to (K*T)*W_t*W_k\n",
    "    probs_flattened = prob_matrices.flatten(0,1)\n",
    "    probs_transposed = probs_flattened.transpose(1,2)\n",
    "    probs_transposed = probs_transposed.to(device)\n",
    "    if type(seq_lens) is torch.Tensor:\n",
    "        seq_lens = seq_lens.tolist()\n",
    "    new_seq_lens=seq_lens*num_keywords\n",
    "    return make_dense_fsa(probs_transposed, new_seq_lens)\n",
    "\n",
    "\n",
    "prob_matrices = torch.randn((num_keywords, batch_size, padded_keyword_len, padded_seq_len))\n",
    "dense_fsa = prepare_dense_fsa_batch(prob_matrices, actual_seq_lens)\n",
    "dense_fsa.dim0(), dense_fsa.device"
   ],
   "id": "8be31be3fdd3ceac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:15:56.813209017Z",
     "start_time": "2025-12-17T02:15:56.768135754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_keyword_batch(prob_matrices, keyword_lens, seq_lens):\n",
    "    num_keywords = prob_matrices.shape[0]\n",
    "    batch_size = prob_matrices.shape[1]\n",
    "    query_fsa = prepare_query_graph(keyword_lens, batch_size)\n",
    "    dense_fsa = prepare_dense_fsa_batch(prob_matrices, seq_lens)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    score = score.reshape(num_keywords, batch_size)\n",
    "    labels = best_path.labels\n",
    "    return score, labels"
   ],
   "id": "27e89503cc8c0118",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T02:15:58.636347887Z",
     "start_time": "2025-12-17T02:15:58.627850127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores, labels = decode_keyword_batch(prob_matrices, keyword_lens, actual_seq_lens)\n",
    "scores.shape, labels.shape"
   ],
   "id": "ee6e694805f77470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 6]), torch.Size([297]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
