{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.310056370Z",
     "start_time": "2025-12-13T05:05:00.266095365Z"
    }
   },
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import k2\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 211
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Decoding multiple test phrases for a single keyword",
   "id": "fd83a285c6c487a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.353295377Z",
     "start_time": "2025-12-13T05:05:00.310364544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 6\n",
    "padded_seq_len = 20\n",
    "actual_seq_lens = [20, 15, 15, 20, 10, 13]\n",
    "keyword_len = 5\n",
    "\n",
    "# probs = torch.randint(1, 20, (batch_size, padded_seq_len, keyword_len))\n",
    "probs = torch.randn((batch_size, padded_seq_len, keyword_len))\n",
    "for i, actual_seq_len in enumerate(actual_seq_lens):\n",
    "    probs[i, actual_seq_len:] = 0\n",
    "# probs = probs.log()\n",
    "probs=probs.to(0)\n",
    "print(probs.shape, probs.device)"
   ],
   "id": "be2ab9503dffe262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 5]) cuda:0\n"
     ]
    }
   ],
   "execution_count": 212
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.397087772Z",
     "start_time": "2025-12-13T05:05:00.353542365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_dense_fsa(log_scores, seq_lens):\n",
    "    N = log_scores.shape[0]\n",
    "\n",
    "    seq_idcs = torch.arange(N, dtype=torch.int32)\n",
    "    start_frames = torch.zeros(N, dtype=torch.int32)\n",
    "    durations = torch.tensor(seq_lens, dtype=torch.int32)\n",
    "\n",
    "    durations_sorted, indices_sorted = torch.sort(durations, descending=True)\n",
    "    seq_idcs_sorted = seq_idcs[indices_sorted]\n",
    "    start_frames_sorted = start_frames[indices_sorted]\n",
    "    log_scores_sorted = log_scores[indices_sorted]\n",
    "\n",
    "    supervision_segments = torch.stack([seq_idcs_sorted, start_frames_sorted, durations_sorted], dim=1)\n",
    "\n",
    "    fsa = k2.DenseFsaVec(log_scores_sorted, supervision_segments)\n",
    "    return fsa"
   ],
   "id": "b2ab8011f8938f20",
   "outputs": [],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.440518452Z",
     "start_time": "2025-12-13T05:05:00.397467371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dense_fsa = make_dense_fsa(probs, actual_seq_lens)\n",
    "dense_fsa.dim0()"
   ],
   "id": "ed4d4524a5fbfd92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 214
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.484268197Z",
     "start_time": "2025-12-13T05:05:00.440849399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_query_fsa_str(keyword_len):\n",
    "    if type(keyword_len) is torch.Tensor:\n",
    "        keyword_len = keyword_len.item()\n",
    "    query_fsa_str = \"\"\n",
    "    for i in range(keyword_len-1):\n",
    "        curr = str(i)+\" \"\n",
    "        nxt = str(i+1)+\" \"\n",
    "        #           src_state   dest_state  label   score\n",
    "        self_arc=   curr +      curr +      curr +  \"0.0\\n\"\n",
    "        arc=        curr +      nxt +       curr +  \"0.0\\n\"\n",
    "        query_fsa_str+=self_arc\n",
    "        query_fsa_str+=arc\n",
    "\n",
    "    penult = str(keyword_len-1)+\" \"\n",
    "    final = str(keyword_len)+\" \"\n",
    "    #                   src_state   dest_state  label   score\n",
    "    final_arc=          penult +    final +     \"-1 \" + \"0.0\\n\"\n",
    "    query_fsa_str +=  final_arc\n",
    "    query_fsa_str += final\n",
    "    return query_fsa_str\n",
    "query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "print(query_fsa_str)"
   ],
   "id": "3622cb4657d5c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0.0\n",
      "0 1 0 0.0\n",
      "1 1 1 0.0\n",
      "1 2 1 0.0\n",
      "2 2 2 0.0\n",
      "2 3 2 0.0\n",
      "3 3 3 0.0\n",
      "3 4 3 0.0\n",
      "4 5 -1 0.0\n",
      "5 \n"
     ]
    }
   ],
   "execution_count": 215
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.528328990Z",
     "start_time": "2025-12-13T05:05:00.484574898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_query_fsa(keyword_len, batch_size=None):\n",
    "    query_fsa_str = get_query_fsa_str(keyword_len)\n",
    "    fsa = k2.Fsa.from_str(query_fsa_str).to(device)\n",
    "    labels = list(range(keyword_len))\n",
    "    # fsa = k2.linear_fsa(labels, device)\n",
    "    # fsa = k2.add_epsilon_self_loops(fsa)\n",
    "\n",
    "    if batch_size is not None:\n",
    "        fsa = k2.create_fsa_vec([fsa]*batch_size)\n",
    "    return fsa\n",
    "\n",
    "query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "query_fsa.shape"
   ],
   "id": "d8fc1b39b1076164",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, None, None)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:05:00.572339158Z",
     "start_time": "2025-12-13T05:05:00.528668633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_single_keyword(probs, seq_lens):\n",
    "    dense_fsa = make_dense_fsa(probs, seq_lens)\n",
    "    keyword_len = probs.shape[-1]\n",
    "    query_fsa = make_query_fsa(keyword_len, batch_size)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    labels = best_path.labels\n",
    "    return score, labels\n",
    "\n",
    "decode_single_keyword(probs, actual_seq_lens)"
   ],
   "id": "51952e7c934c1652",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1785, 6.9284, 5.5624, 7.6326, 3.0374, 5.2211], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([ 0,  1,  1,  1,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3, -1,  0,  1,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3,  3, -1,  0,  0,  0,  0,  0,  1,  2,  2,  2,  2,  2,  2,\n",
       "          2,  2,  3, -1,  0,  1,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3, -1,  0,  0,  0,  0,  0,  1,  1,  1,  2,  3,  3,  3,  3, -1,  0,  0,\n",
       "          0,  1,  1,  1,  1,  2,  2,  3, -1], device='cuda:0',\n",
       "        dtype=torch.int32))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 217
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(tensor([ 7.8563, 20.5448,  4.5942,  9.5775,  3.4156,  1.4157], device='cuda:0',\n",
    "        dtype=torch.float64),\n",
    " tensor([ 0,  0,  0,  0,  0,  1,  2,  3,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0, -1,  0,  0,  1,  0,  0,  0,  0,  0,  2,  3,  4,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0, -1,  0,  1,  2,  3,  4,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  2,  0,  3,  0,  4,\n",
    "          0, -1,  0,  1,  0,  0,  2,  0,  3,  0,  0,  4,  0,  0,  0, -1,  0,  0,\n",
    "          1,  0,  2,  3,  0,  4,  0,  0, -1], device='cuda:0',\n",
    "        dtype=torch.int32))"
   ],
   "id": "ddd1f51163eff2b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batched keyword decoding",
   "id": "2bb8322ead485e53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:13:22.941585433Z",
     "start_time": "2025-12-13T05:13:22.934158588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_query_graph(keyword_lens, batch_size):\n",
    "    \"\"\"\n",
    "    Creates an FSA Vector with `batch_size` repetitions\n",
    "    of each query graph.\n",
    "\n",
    "    Arguments:\n",
    "        keyword_lens: list of lengths of each query graph\n",
    "        batch_size: number of test phrases in batch\n",
    "    Returns:\n",
    "        FSA vector of queries\n",
    "    \"\"\"\n",
    "    expanded_lens = torch.tensor(keyword_lens)\\\n",
    "        .unsqueeze(1)\\\n",
    "        .repeat(1, batch_size)\\\n",
    "        .view(-1)\\\n",
    "        .to(torch.int32)\n",
    "    fsa_list = []\n",
    "    for keyword_len in expanded_lens:\n",
    "        fsa_list.append(make_query_fsa(keyword_len))\n",
    "    query_graph = k2.create_fsa_vec(fsa_list)\n",
    "    return query_graph\n",
    "\n",
    "keyword_lens = [10, 5, 9]\n",
    "padded_keyword_len = max(keyword_lens)\n",
    "num_keywords = len(keyword_lens)\n",
    "\n",
    "query_graph = prepare_query_graph(keyword_lens, batch_size)\n",
    "query_graph.shape"
   ],
   "id": "fcfeaad645ea6b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, None, None)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:14:16.076069273Z",
     "start_time": "2025-12-13T05:14:16.053989718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_dense_fsa_batch(prob_matrices: torch.Tensor, seq_lens: Sequence[int]):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        prob_matrices: tensor of shape K*T*W_k*W_t, where K is the number of queries,\n",
    "            T the number of test phrases, W_k the number of padded windows in each\n",
    "            query and W_t the number of padded windows in each test phrase\n",
    "    Returns:\n",
    "        Dense FSA of query probabilities\n",
    "    \"\"\"\n",
    "    # prob_matrices needs to be reshaped from K*T*W_k*W_t\n",
    "    # to (K*T)*W_t*W_k\n",
    "    probs_flattened = prob_matrices.flatten(0,1)\n",
    "    probs_transposed = probs_flattened.transpose(1,2)\n",
    "    probs_transposed = probs_transposed.to(device)\n",
    "    if type(seq_lens) is torch.Tensor:\n",
    "        seq_lens = seq_lens.tolist()\n",
    "    new_seq_lens=seq_lens*num_keywords\n",
    "    return make_dense_fsa(probs_transposed, new_seq_lens)\n",
    "\n",
    "\n",
    "prob_matrices = torch.randn((num_keywords, batch_size, padded_keyword_len, padded_seq_len))\n",
    "dense_fsa = prepare_dense_fsa_batch(prob_matrices, actual_seq_lens)\n",
    "dense_fsa.dim0(), dense_fsa.device"
   ],
   "id": "8be31be3fdd3ceac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:14:18.777143647Z",
     "start_time": "2025-12-13T05:14:18.732566766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_keyword_batch(prob_matrices, keyword_lens, seq_lens):\n",
    "    batch_size = prob_matrices.shape[1]\n",
    "    query_fsa = prepare_query_graph(keyword_lens, batch_size)\n",
    "    dense_fsa = prepare_dense_fsa_batch(prob_matrices, seq_lens)\n",
    "\n",
    "    lattice = k2.intersect_dense(query_fsa, dense_fsa, output_beam=10.0)\n",
    "    best_path = k2.shortest_path(lattice, use_double_scores=True)\n",
    "    score = best_path.get_tot_scores(use_double_scores=True, log_semiring=True)\n",
    "    labels = best_path.labels\n",
    "    return score, labels"
   ],
   "id": "27e89503cc8c0118",
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-13T05:14:38.192032565Z",
     "start_time": "2025-12-13T05:14:38.168378628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores, labels = decode_keyword_batch(prob_matrices, keyword_lens, actual_seq_lens)\n",
    "scores.shape, labels.shape"
   ],
   "id": "ee6e694805f77470",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18]), torch.Size([297]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 234
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
