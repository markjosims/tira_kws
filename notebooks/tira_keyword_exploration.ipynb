{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82eee54c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:30:10.020192Z",
     "start_time": "2025-12-11T09:30:10.015698Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b2a393a-23eb-454d-8d4f-f3446ddc3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1337\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6250358acd96d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:28:18.831386Z",
     "start_time": "2025-12-11T09:28:18.825214Z"
    }
   },
   "outputs": [],
   "source": [
    "# using this until I figure out how to set jupyter working dir in PyCharm\n",
    "import os\n",
    "project_dir = os.path.expanduser('~/projects/tira_kws')\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39df6e8132429065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:29:12.132790Z",
     "start_time": "2025-12-11T09:29:12.123183Z"
    }
   },
   "outputs": [],
   "source": [
    "# local imports\n",
    "from dataloading import load_tira_asr\n",
    "from constants import (\n",
    "    PHRASELIST_PATH, MERGED_PHRASES_CSV,\n",
    "    KEYPHRASE_CSV, CER_MATRIX_PATH, CALIBRATION_LIST\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2a68f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:30:16.059583Z",
     "start_time": "2025-12-11T09:30:13.768293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'start', 'end', 'transcription', 'eaf_source', 'wav_source', 'raw_transcription', 'clip', 'wav_rawpath', 'path', 'allosaurus', 'clap_ipa_cos_sim', 'wada_snr', 'nist_stnr', 'speaker-diarization-3.1', 'voice-activity-detection', 'whisper-large-v3', 'clapipa-transcription-allosaurus', 'vad_s', 'drz_s', 'trans_len', 'pcnt_speech', 'trans_len_sq', 'trans_len_log', 'cos_sim_softmax', 'cos_sim_log', 'duration', 'filestem', 'rewritten_transcript'],\n",
       "    num_rows: 20480\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=load_tira_asr()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb725b25",
   "metadata": {},
   "source": [
    "## Merged transcripts\n",
    "Find instances where FST normalization caused several dissimilar hand-transcribed sentences to merge and save as a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3fb2a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:30:40.616008Z",
     "start_time": "2025-12-11T09:30:40.536979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eaf_text</th>\n",
       "      <th>fst_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>àprí jɜ̀dí ðáŋàlà</td>\n",
       "      <td>àpɾí jàdí ðáŋàlà</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>àprí jɜ̀dí ðáŋàlà</td>\n",
       "      <td>àpɾí jàdí ðáŋàlà</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "      <td>àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "      <td>àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "      <td>àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        eaf_text                       fst_text\n",
       "0        àprí jɜ̀dí ðáŋàlà        àpɾí jàdí ðáŋàlà\n",
       "1        àprí jɜ̀dí ðáŋàlà        àpɾí jàdí ðáŋàlà\n",
       "2  àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà  àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà\n",
       "3  àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà  àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà\n",
       "4  àprí jə̀və̀lɛ̀ðɔ́ ðáŋàlà  àpɾí jə̀və̀lɛ̀ðɔ́ ðáŋàlà"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colmap = {'transcription': 'eaf_text', 'rewritten_transcript': 'fst_text'}\n",
    "cols_to_drop = set(ds.column_names)-set(colmap.keys())\n",
    "ds_noaudio = ds.remove_columns(cols_to_drop)\n",
    "df = ds_noaudio.to_pandas()\n",
    "df = df.rename(columns=colmap)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6f5a9f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:31:05.044454Z",
     "start_time": "2025-12-11T09:30:47.729185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8350/8350 [00:05<00:00, 1578.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8350, 9399)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fst_to_eaf = {}\n",
    "fst_unique = df['fst_text'].unique().tolist()\n",
    "eaf_unique = df['eaf_text'].unique().tolist()\n",
    "eaf_strs_encountered = set()\n",
    "for fst_text in tqdm(fst_unique):\n",
    "    mask = df['fst_text'] == fst_text\n",
    "    eaf_text = df.loc[mask, 'eaf_text'].unique().tolist()\n",
    "    fst_to_eaf[fst_text] = eaf_text\n",
    "    # ensure only one FST str per EAF str\n",
    "    assert not any(eaf_str in eaf_strs_encountered for eaf_str in eaf_text)\n",
    "    eaf_strs_encountered.update(*eaf_text)\n",
    "len(fst_unique), len(eaf_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d77a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20480, 2) (9399, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eaf_text</th>\n",
       "      <th>fst_text</th>\n",
       "      <th>num_eaf_variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>ɛ̀màðɛ̀lí kìcə̀lò</td>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>ɛ̀màðàlʊ́ kìcə̀lò</td>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>àmàð kìclò</td>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>lə̀və̀lɛ̀ðɜ̂lló únɛ́rɛ̀</td>\n",
       "      <td>lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>lə̀və̀lɛ̀ðálírló únɛ́ɾɛ̀</td>\n",
       "      <td>lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eaf_text                   fst_text  \\\n",
       "5821         ɛ̀màðɛ̀lí kìcə̀lò           ɛ̀màð kìcə̀lò   \n",
       "5819         ɛ̀màðàlʊ́ kìcə̀lò           ɛ̀màð kìcə̀lò   \n",
       "7495                àmàð kìclò           ɛ̀màð kìcə̀lò   \n",
       "930      lə̀və̀lɛ̀ðɜ̂lló únɛ́rɛ̀  lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́   \n",
       "1308  lə̀və̀lɛ̀ðálírló únɛ́ɾɛ̀  lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́   \n",
       "\n",
       "      num_eaf_variants  \n",
       "5821                 7  \n",
       "5819                 7  \n",
       "7495                 7  \n",
       "930                  7  \n",
       "1308                 7  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eaf_unique_df = df.drop_duplicates(subset=['eaf_text'])\n",
    "eaf_unique_df = eaf_unique_df.reset_index(drop=True)\n",
    "print(df.shape, eaf_unique_df.shape)\n",
    "\n",
    "eaf_unique_df['num_eaf_variants'] = eaf_unique_df['fst_text']\\\n",
    "    .apply(fst_to_eaf.get)\\\n",
    "    .apply(len)\n",
    "eaf_unique_df = eaf_unique_df.sort_values('num_eaf_variants', ascending=False)\n",
    "# eaf_unique_df = eaf_unique_df.set_index('fst_text')\n",
    "eaf_unique_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0cbd62754e887",
   "metadata": {},
   "source": [
    "How many unique EAF strings do we have per FST-normalized string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea5c4d9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:28:37.561203Z",
     "start_time": "2025-12-11T09:28:33.997081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_eaf_variants\n",
       "1    7484\n",
       "2    1440\n",
       "3     366\n",
       "4      68\n",
       "5      15\n",
       "7      14\n",
       "6      12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eaf_unique_df['num_eaf_variants'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1071009a72fa68",
   "metadata": {},
   "source": [
    "Ignore EAF text, make a `DataFrame` with only unique FST strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4224796b-0a27-40d7-b584-f937adfa5681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8350,), (8350,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eaf_unique_df['fst_text'].unique().shape,\\\n",
    "df['fst_text'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84e87189-1d15-4ac0-9f21-25fcf3bdccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eaf_unique_df.to_csv(MERGED_PHRASES_CSV, index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d6824-8b66-426c-9f9f-e92112684f7e",
   "metadata": {},
   "source": [
    "## Make dataframe of unique phrases\n",
    "Now that we've explored the mapping between FST strings and EAF stings, let's make a `DataFrame` that has a single row for each unique FST string and add a column `token_counts` that indicates the number of times each string occurs in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae37c61c-4af8-41d7-ad9d-863e704fd6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8350, 2), (9399, 3))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_df = eaf_unique_df.drop(columns='eaf_text')\n",
    "unique_phrase_df = unique_phrase_df.drop_duplicates(subset='fst_text')\n",
    "unique_phrase_df.shape, eaf_unique_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ae52b3c-f054-4bc8-82e8-a8036b18975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fst_text</th>\n",
       "      <th>num_eaf_variants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>íŋgá ɾɔ́ðà</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          fst_text  num_eaf_variants\n",
       "5821              ɛ̀màð kìcə̀lò                 7\n",
       "930      lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́                 7\n",
       "536                  íŋgá ɾɔ́ðà                 6\n",
       "265   láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀                 6\n",
       "372         kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́                 5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92b145db-980f-43e9-a64d-d39ad998b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fst_text</th>\n",
       "      <th>num_eaf_variants</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>íŋgá ɾɔ́ðà</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fst_text  num_eaf_variants  token_count\n",
       "0              ɛ̀màð kìcə̀lò                 7           10\n",
       "1     lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́                 7           19\n",
       "2                 íŋgá ɾɔ́ðà                 6           11\n",
       "3  láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀                 6           18\n",
       "4        kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́                 5           10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts = df['fst_text'].value_counts()\n",
    "\n",
    "# change index to ensure count is properly mapped to respective string\n",
    "unique_phrase_df = unique_phrase_df.set_index('fst_text')\n",
    "unique_phrase_df['token_count'] = token_counts\n",
    "\n",
    "# sanity check\n",
    "for _ in range(100):\n",
    "    i = random.randint(0, len(unique_phrase_df))\n",
    "    curr_keyphrase = unique_phrase_df.index[i]\n",
    "    assert token_counts[curr_keyphrase] ==\\\n",
    "        unique_phrase_df.at[curr_keyphrase, 'token_count'].item()\n",
    "\n",
    "# reset index to clean up\n",
    "unique_phrase_df = unique_phrase_df.reset_index()\n",
    "unique_phrase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b040e66-6422-4694-a391-36e9af563688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8350.000000\n",
       "mean        2.452695\n",
       "std         1.711873\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         3.000000\n",
       "max        21.000000\n",
       "Name: token_count, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_df['token_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e86ed9-7eb0-45f6-8ecb-21e644b7331e",
   "metadata": {},
   "source": [
    "Get a list of all phrases. The order of this list will be used to index positive and negative keyphrase tokens in the keyphrase dataset to be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a0904a3-c966-4eb7-8c31-912684928269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8350,\n",
       " ['ɛ̀màð kìcə̀lò',\n",
       "  'lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́',\n",
       "  'íŋgá ɾɔ́ðà',\n",
       "  'láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀',\n",
       "  'kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_phrases = unique_phrase_df['fst_text'].tolist()\n",
    "len(all_phrases), all_phrases[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6490a50",
   "metadata": {},
   "source": [
    "## Keyphrase selection\n",
    "Visualize keyphrases with 10 or more tokens and select the set to be used for KWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81fd7835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:57:14.642403Z",
     "start_time": "2025-12-11T03:57:14.624239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ɛ̀màð kìcə̀lò',\n",
       "  'lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́',\n",
       "  'íŋgá ɾɔ́ðà',\n",
       "  'láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀',\n",
       "  'kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́'],\n",
       " (56, 4))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_mask = unique_phrase_df['token_count'] >= 10\n",
    "unique_phrase_df['is_keyphrase'] = keyphrase_mask\n",
    "high_freq_phrases = unique_phrase_df[keyphrase_mask]['fst_text'].tolist()\n",
    "high_freq_phrases[:5], unique_phrase_df[keyphrase_mask].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121d34dbcb0b9ff",
   "metadata": {},
   "source": [
    "We have 56 unique keyphrases with 10 or more occurrences. We'll define these as our keyword set.\n",
    "\n",
    "Let's do some introspection on these keywords, starting with the distribution of their string length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "912742da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:43:26.181425Z",
     "start_time": "2025-12-11T03:43:26.166424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    56.000000\n",
       "mean     21.285714\n",
       "std       8.307093\n",
       "min       5.000000\n",
       "25%      15.000000\n",
       "50%      22.000000\n",
       "75%      26.000000\n",
       "max      40.000000\n",
       "Name: fst_text, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(unique_phrase_df[keyphrase_mask]['fst_text'].str.len()).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd6d7f8",
   "metadata": {},
   "source": [
    "Get negative keyphrases based on CER from positive keyphrase.\n",
    "\n",
    "First, make a distance matrix showing pairwise CER between keyphrases and all sentences.\n",
    "Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b8fbf58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:49:17.771257Z",
     "start_time": "2025-12-11T03:44:09.134491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:06<00:00,  8.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.375     , 0.875     , 1.3125    , 1.125     ],\n",
       "       [0.88      , 0.        , 0.84      , 0.84      , 0.24      ],\n",
       "       [1.07692308, 1.61538462, 0.        , 1.69230769, 1.46153846],\n",
       "       [0.75      , 0.75      , 0.78571429, 0.        , 0.71428571],\n",
       "       [0.81818182, 0.27272727, 0.86363636, 0.90909091, 0.        ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jiwer import cer, process_characters\n",
    "import numpy as np\n",
    "\n",
    "cer_matrix = np.zeros((keyphrase_mask.sum(), len(all_phrases)), dtype=float)\n",
    "for i, phrase1 in tqdm(enumerate(high_freq_phrases), total=len(high_freq_phrases)):\n",
    "    for j, phrase2 in enumerate(all_phrases):\n",
    "        dist = cer(phrase1, phrase2)\n",
    "        cer_matrix[i, j] = dist\n",
    "cer_matrix[:5,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7681d57f",
   "metadata": {},
   "source": [
    "Now, for each positive keyphrase, bucket negative keyphrases based on the ratio of the edit distance to the keyphrase's length.\n",
    "Then sample 30 keywords from 0-33% edit distance/length (hard), 33-66% (medium) and 66-100% (easy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e24aeb08109eb3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:56:36.226467Z",
     "start_time": "2025-12-11T03:56:35.579140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fst_text</th>\n",
       "      <th>num_eaf_variants</th>\n",
       "      <th>token_count</th>\n",
       "      <th>is_keyphrase</th>\n",
       "      <th>num_easy</th>\n",
       "      <th>num_medium</th>\n",
       "      <th>num_hard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ɛ̀màð kìcə̀lò</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>7801</td>\n",
       "      <td>450</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>7652</td>\n",
       "      <td>627</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>íŋgá ɾɔ́ðà</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>True</td>\n",
       "      <td>8152</td>\n",
       "      <td>184</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>6922</td>\n",
       "      <td>1310</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>7673</td>\n",
       "      <td>595</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fst_text  num_eaf_variants  token_count  is_keyphrase  \\\n",
       "0              ɛ̀màð kìcə̀lò                 7           10          True   \n",
       "1     lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́                 7           19          True   \n",
       "2                 íŋgá ɾɔ́ðà                 6           11          True   \n",
       "3  láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀                 6           18          True   \n",
       "4        kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́                 5           10          True   \n",
       "\n",
       "   num_easy  num_medium  num_hard  \n",
       "0      7801         450        98  \n",
       "1      7652         627        70  \n",
       "2      8152         184        13  \n",
       "3      6922        1310       117  \n",
       "4      7673         595        81  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_df['num_easy'] = 0\n",
    "unique_phrase_df['num_medium'] = 0\n",
    "unique_phrase_df['num_hard'] = 0\n",
    "\n",
    "for keyphrase_idx, keyphrase in enumerate(high_freq_phrases):\n",
    "    keyphrase_len = len(keyphrase)\n",
    "\n",
    "    dists_to_keyphrase = cer_matrix[keyphrase_idx, :]\n",
    "\n",
    "    easy_mask = dists_to_keyphrase > 0.67\n",
    "    medium_mask = (dists_to_keyphrase <= 0.67) & (dists_to_keyphrase > 0.33)\n",
    "    hard_mask = (dists_to_keyphrase > 0) & (dists_to_keyphrase <= 0.33)\n",
    "\n",
    "    curr_keyphrase_mask = unique_phrase_df['fst_text'] == keyphrase\n",
    "    unique_phrase_df.loc[curr_keyphrase_mask, 'num_easy'] = easy_mask.sum()\n",
    "    unique_phrase_df.loc[curr_keyphrase_mask, 'num_medium'] = medium_mask.sum()\n",
    "    unique_phrase_df.loc[curr_keyphrase_mask, 'num_hard'] = hard_mask.sum()\n",
    "\n",
    "unique_phrase_df[keyphrase_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea2608027993d63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T03:57:19.270761Z",
     "start_time": "2025-12-11T03:57:19.259904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7701.267857142857, 614.0535714285714, 33.67857142857143)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_phrase_df[keyphrase_mask]['num_easy'].mean(),\\\n",
    "unique_phrase_df[keyphrase_mask]['num_medium'].mean(),\\\n",
    "unique_phrase_df[keyphrase_mask]['num_hard'].mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "499d13d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T04:01:36.259732Z",
     "start_time": "2025-12-11T04:01:36.203593Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_phrase_df[keyphrase_mask].to_csv(KEYPHRASE_CSV, index_label='index')\n",
    "np.save(CER_MATRIX_PATH, cer_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f4ecc-2523-4738-9847-1e1b56e027bf",
   "metadata": {},
   "source": [
    "# Keyphrase lists\n",
    "Define lists of positive and negative records for each keyphrase.\n",
    "\n",
    "## Calibration set\n",
    "- 10 positive samples\n",
    "- 50 negative samples for easy, medium and hard\n",
    "- use to tune $\\tau$ threshold\n",
    "\n",
    "## Evaluation set\n",
    "- use all positive and negative samples\n",
    "- use macro-averaging\n",
    "\n",
    "English negative samples will be handled separately since those are the same across all keyphrases.\n",
    "\n",
    "## Output\n",
    "JSON object looks like:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        'keyphrase': $str,\n",
    "        'keyphrase_idx': $int,\n",
    "        'record_idcs': [$int, $int, ...]\n",
    "        'easy': {\n",
    "            'phrase_idcs': [$int, $int, ...]\n",
    "            'record_idcs': [$int, $int, ...]\n",
    "        },\n",
    "        'medium': {...},\n",
    "        'hard': {...},\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89c6b300-f23d-4367-8020-9c20ab490d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ɛ̀màð kìcə̀lò',\n",
       " 'lə̀və̀lɛ̀ðɜ́lló únɛ́ɾɛ́',\n",
       " 'láló və́lɛ̀ðà nd̪ɔ̀bàgɛ̀',\n",
       " 'kə̀və̀lɛ̀ðɔ́l ùnɛ́ɾɛ́',\n",
       " 'lɛ̀ĺ və́lɛ̀ðɛ̀ ùnɛ́ɾɛ́']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_num_negative = 50\n",
    "\n",
    "has_easy = unique_phrase_df['num_easy'] >= calibration_num_negative\n",
    "has_medium = unique_phrase_df['num_medium'] >= calibration_num_negative\n",
    "has_hard = unique_phrase_df['num_hard'] >= calibration_num_negative\n",
    "\n",
    "has_negative = has_easy & has_medium & has_hard\n",
    "calibration_keyphrases = unique_phrase_df.loc[has_negative, 'fst_text'].tolist()\n",
    "unique_phrase_df['in_calibration_set'] = has_negative\n",
    "print(has_negative.sum(), len(high_freq_phrases))\n",
    "calibration_keyphrases[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "94239381-6dc6-426c-981a-44a63c41f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyphrase_list = []\n",
    "calibration_list = []\n",
    "\n",
    "\n",
    "for keyphrase_i, keyphrase in enumerate(high_freq_phrases):\n",
    "    dists_to_keyphrase = cer_matrix[keyphrase_i, :]\n",
    "    keyphrase_mask = unique_phrase_df['fst_text'] == keyphrase\n",
    "    row = unique_phrase_df[keyphrase_mask]\n",
    "    assert len(row) == 1\n",
    "    row = row.iloc[0]\n",
    "\n",
    "    # add positive rows\n",
    "    keyphrase_obj['keyphrase'] = keyphrase\n",
    "    keyphrase_obj['keyphrase_idx'] = keyphrase_i\n",
    "    keyphrase_obj['records_idcs'] = \n",
    "    \n",
    "    # add negative rows\n",
    "    \n",
    "    easy_mask = dists_to_keyphrase > 0.67\n",
    "    medium_mask = (dists_to_keyphrase <= 0.67) & (dists_to_keyphrase > 0.33)\n",
    "    hard_mask = (dists_to_keyphrase > 0) & (dists_to_keyphrase <= 0.33)\n",
    "\n",
    "    for mask, split in (easy_mask, 'easy'), (medium_mask, 'medium'), (hard_mask, 'hard'):\n",
    "        all_negative_rows = np.argwhere(mask).tolist()\n",
    "        keyphrase_list[keyphrase][split] = all_negative_rows\n",
    "        if row['in_calibration_set']:\n",
    "            calibration_negative_rows = random.sample(all_negative_rows, calibration_num_negative)\n",
    "            calibration_list[keyphrase][split] = calibration_negative_rows\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bd4dda0-9866-4554-83db-c5af3308440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CALIBRATION_LIST, encoding='utf8', mode='w') as f:\n",
    "    ...    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
